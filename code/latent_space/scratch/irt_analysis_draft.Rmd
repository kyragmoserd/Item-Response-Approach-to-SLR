---
title: "INSERT A GOOD TITLE HERE"
output:
  bookdown::pdf_document2: default
  bookdown::html_document2: default
---



hypotheses

H1 -dimensions on which things organize
  tensions:
    top down vs. bottom up
    regional vs. local
    economic infrastructure vs. environment
H2 -org type
H3 -psychological distance
H4 -involvement



**INTRODUCTION**  
- ecology of games  
- network management  
- case of sea level rise  
- application of IRT to understand multidimensional policy spaces

**BACKGROUND**  
- sea level rise as general problem  
- sea level rise in case of Bay Area  
- regional governance efforts  

**RATIONALE**  
- governance as a multi-actor situation without formal hierarchy, instead largely horizontal approaches to steering and decision-making (e..g, Klijn et a. 2010).  
- theory about network management (klijn/edelenbos, provan/kenis), EG framework (Lubell, Berardo), perhaps a little ACF  
- preferred management strategies and policy tools as a function of the portfolio of issues someone is concerned about  
- research questions:  


```{r startup_code, echo = F,message=F,results='hide',warning=F}
DROP_BARRIERS = TRUE
RERUN_MIRT = FALSE
seed = 24

packs =c('tidyverse','purrr','data.table','statnet','latentnet','bipartite','lvm4net','mirt','pbapply',
         'ggthemes','here','ggnetwork','gridExtra','ggrepel','corrplot','htmlTable','readxl','nFactors','ggrepel','plotly','ggalluvial')
need = packs[!packs %in% names(installed.packages()[,2])]
invisible(sapply(need,function(x) suppressMessages(install.packages(x,type= 'source'))))
invisible(sapply(packs,function(x) suppressMessages(library(x,character.only = T))))



old = theme_set(theme_bw())
orig = readxl::read_excel('input/SLRSurvey_Full.xlsx')
orig$Q4[is.na(orig$Q4)]<-'Other'
#recode anything with fewer than 10 respondents as other
# see what wed recode
#as.data.table(table(orig$Q4))[order(-N),][N<10,]
orig$Q4[orig$Q4 %in% as.data.table(table(orig$Q4))[order(-N),][N<10,]$V1] <- 'Other'
orig$Q4[grepl('Other',orig$Q4)]<-'Other'
incidence_dt = fread("CurrentFiles/Data/AdjMatrix_MinOtherRecode.csv")

incidence_mat = as.matrix(incidence_dt[,-c('ResponseId','DK')])
rownames(incidence_mat)<-incidence_dt$ResponseId
#drop isolates
incidence_mat = incidence_mat[rowSums(incidence_mat)!=0,]
incidence_mat = incidence_mat[,!grepl('Other',colnames(incidence_mat))]

#create network object
bip_net = as.network(incidence_mat,matrix.type = 'incidence',bipartite = T,directed = F,loops = F)
#code actor types
bip_net %v% 'Actor_Type' <- orig$Q4[match(network.vertex.names(bip_net),orig$ResponseId)]
#code concept types
concept_types = fread('input/Combined_VectorTypes_NoNewOther.csv')
bip_net %v% 'Concept_Type' <- concept_types$Type[match(network.vertex.names(bip_net), concept_types$Vector)]
set.vertex.attribute(bip_net,'Concept_Type',value = 'Person',v = which(is.na(bip_net %v% 'Concept_Type')))

bip_net %v% 'id' <- network.vertex.names(bip_net)
bip_net %v% 'id_concept' <- ifelse({bip_net %v% 'Concept_Type'} == 'Person',network.vertex.names(bip_net),bip_net %v% 'Concept_Type')

bip_net %v% 'b1_dummy_b2_names' <- ifelse({bip_net %v% 'Concept_Type'} == 'Person','Person',bip_net %v% 'vertex.names')

#DROP BARRIERS#
if(DROP_BARRIERS){
bip_net = get.inducedSubgraph(x = bip_net,v = which(bip_net %v% 'Concept_Type' != 'Barrier'))
}
#convert to incidence matrix
Y = as.sociomatrix(bip_net)
Y = Y[,!grepl('Other',colnames(Y))]
Y<-Y[,sort(colnames(Y))]

#make predictor dt
predictor_dt = data.table(id = rownames(Y))
predictor_dt$Q1_Focus <- orig$Q1_Num[match(predictor_dt$id,orig$ResponseId)]
predictor_dt$When_SLR <- orig$WhenSLR[match(predictor_dt$id,orig$ResponseId)]
predictor_dt$Q16_Risk_Agree <- orig$RiskAgree[match(predictor_dt$id,orig$ResponseId)]
predictor_dt$Q17_Action_Agree <- orig$ActionAgree[match(predictor_dt$id,orig$ResponseId)]

predictor_dt$Q1_Focus[is.na(predictor_dt$Q1_Focus)]<-round(mean(predictor_dt$Q1_Focus,na.rm = T))
predictor_dt$When_SLR[is.na(predictor_dt$When_SLR)]<-round(mean(predictor_dt$When_SLR,na.rm = T))
predictor_dt$Q16_Risk_Agree[is.na(predictor_dt$Q16_Risk_Agree)]<-round(mean(predictor_dt$Q16_Risk_Agree,na.rm = T))
predictor_dt$Q17_Action_Agree[is.na(predictor_dt$Q17_Action_Agree)]<-round(mean(predictor_dt$Q17_Action_Agree,na.rm = T))

```

**METHODS AND MATERIALS**  

**Data**  
- survey design and implementation  
- response statistics (sample, response rate, etc.)  
- basic survey descriptives  
  - summary table of actor train responses (experience, org type, etc.)  
  - three panel plot bar plot of frequency of choices for each of concerns, barriers, policies  
Figure \@ref(fig:figure-choice-percentages) shows the percentage of respondents who selected each item.

```{r figure-choice-percentages, echo = F,message = F,warning = F,fig.cap = 'Frequency of response choices in sample'}

mY = melt(Y)
mY$cat = {bip_net %v% 'Concept_Type'}[match(mY$Var2,bip_net %v% 'vertex.names')]
mY<-data.table(mY)
mY = mY[,mean(value),by=.(Var2,cat)][order(-V1)]
mY$fact = fct_reorder(mY$Var2,mY$V1,mean)

#ideally this would be a fact_wrap call but getting factors to drop out takes some effort
plist = list(ggplot(mY[cat =='Concern',]) + geom_point(aes(x = fact,y = 100 * V1))+
               geom_text(aes(x = fact,y = 100 * V1 +5,label = fact),hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + 
  theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip(),
ggplot(mY[cat =='Policy',]) + geom_point(aes(x = fact,y = 100 * V1))+
               geom_text(aes(x = fact,y = 100 * V1 +5,label = fact),hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + 
  theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip(),
if(!DROP_BARRIERS){
ggplot(mY[cat =='Barrier',]) + geom_point(aes(x = fact,y = 100 * V1))+
              geom_text(aes(x = fact,y = 100 * V1 +5,label = fact), hjust = 0) + scale_y_continuous(limits = c(0,100)) +facet_wrap(~cat) + theme_bw() + theme(axis.title = element_blank(),axis.text.y = element_blank(),axis.ticks.y= element_blank())+coord_flip()}else{NULL})

if(DROP_BARRIERS){grid.arrange(plist[[1]],plist[[2]],bottom= 'Respondent selection #',ncol=2)}
if(!DROP_BARRIERS){grid.arrange(plist[[1]],plist[[2]],plist[[3]],bottom= 'Respondent selection #',ncol=3)}
```
  
  
**Model**


Survey respondents identified up to three (each) from a range of issues and strategies. Thus, each respondent is linked to between 0 and 6 system components. We are interested both in how different issues, barriers, and strategies assort into different "policy portfolios". The basic conceit of an IRT model is that observed choices reflect latent traits--in this case, we conceptualize these traits as representing core policy beliefs or underlying policy goals and motivations. The goal is to represent respondents' choices for the `r ncol(Y)` concept options on a reduced set of underlying dimensions. IRT models leverage the relative discriminatory power of different responses (e.g., some responses differ greatly between groups while others do now, and some responses are rare while others are more common) estimation each respondents' position on the latent trait dimensions.

There are many different IRT model approaches. Our approach is exploratory and multidimensional. Exploratory means that, just like an exploratory factor model, we do not assign specific responses to each latent dimension, but instead estimate the underlying relationships between every measured response and latent trait. Multidimensional simply means that we fit more than one latent trait, or dimension. 

The specific IRT model approach we used is a dichotomous ideal-point model (Maydeu-Olivares, 2006). Dichotomous simply refers to the fact that each response is a 0/1 observation. Classic IRT application such as aptitude testing assume a cumulative response function, where the relationship between a latent trait and response probability is monotonically increasing (Tay and Ng 2018) -- for instance, if someone is more intelligent than their probability of answering each question on a test right should increase. This is not the case for constructs such as policy beliefs, which have "ideal point properties", i.e., a non-monotonic relationship between traits and responses. For this reason, ideal point models are commonly used to estimate political ideology and other policy/political attitudes (e.g., Bertelli and Grose 2011, Clinton et al. 2012, Shor et al. 2010). 


We use the *mirt* package in R (cite package) for all estimation. The *mirt* package employs a multidimensional ideal point model for binary data developed by Maydeu-Olivares (2006). Responses are represented as a binary incidence matrix X~~nm, were *N* is the number of respondents and *M* is the # of response items. Each item is treated ordinally (since all responses were yes/no measures).  The number of trait dimensions is preset prior to model fitting. We assume that one key dimension in the latent policy space is likely to reflect the class divide between pro-development and pro-environment interests. However, many of the issues and policies addressed in the survey do not map cleanly onto this spectrum. Instead, many choices reflect respondents' views on local versus top-down oriented management approaches, built versus institutional infrastructure, and other features of the policy space. Thus, we test a series of multidimensional IRT models from 1 to 5 dimensions for goodness-of-fit. 

```{r,message = F}
if(RERUN_MIRT){
#make 4 cores available for parallel computing
mirtCluster(4)
dims = 1:5
#no covariates
bare_mods = lapply(dims,function(d) mirt(data = Y,model = d,itemtype = 'ideal',method = ifelse(d<3,'EM','QMCEM')))
saveRDS(object = bare_mods,file = 'scratch/mirt_base.rds')
}
if(!RERUN_MIRT){bare_mods = readRDS('scratch/mirt_base.rds')}
```

**Model Fit**

```{r}
gof_tab = data.table(dimensions = dims,t(sapply(bare_mods,function(x) round(anova(x)[c('AIC','BIC','SABIC')],2))))
htmlTable(gof_tab)
best_mod = 1#which.min(gof_tab$SABIC)

```




<!-- ```{r} -->
<!-- #two factors (exploratory) -->
<!-- mod2 = bare_mods[[2]] -->

<!-- ld2 = summary(mod2,rotate = 'oblimin') -->
<!-- ld2dt = data.table(ld2$rotF,item= rownames(ld2$rotF)) -->
<!-- ld2dt_melt = melt(ld2dt) -->

<!-- ggplot(ld2dt_melt,aes(y = item,x = value)) + facet_wrap(~variable,nrow = 1) +  -->
<!--   geom_segment(aes(y = item,yend = item,x = 0,xend = value))+ -->
<!--   geom_point(aes(color = value),size = 3) + -->
<!--   scale_color_viridis_c() + guides(color = 'none')+ -->
<!--   scale_x_continuous(name = 'Factor loadings by item and latent trait dimension') +  -->
<!--   theme_bw() -->
<!-- ``` -->



```{r}
#three factors (exploratory)
best_mod = 2
mod3 = bare_mods[[best_mod]]

ld3 = summary(mod3,rotate = 'oblimin')
ld3dt = data.table(ld3$rotF,item= rownames(ld3$rotF))
#ld3dt_melt = melt(ld3dt)
?mirt::`summary-method`
#ld3dt_melt$item <- fct_reorder(ld3dt_melt$item,ld3dt_melt$value)

ggplot(ld3dt_melt[order(-value)&variable == 'F1',],aes(y = item,x = value)) + facet_wrap(~variable,nrow = 1) + 
  geom_segment(aes(y = item,yend = item,x = 0,xend = value))+
  geom_point(aes(color = value),size = 3) +
  scale_color_viridis_c() + guides(color = 'none')+
  scale_x_continuous(name = 'Factor loadings by item and latent trait dimension') + 
  theme_bw()



g1 = ggplot(ld3dt[order(-F1),] %>% mutate(item = fct_reorder(item,F1)),aes(y = item,x = F1)) + 
  geom_segment(aes(y = item,yend = item,x = 0,xend = F1))+
  geom_point(aes(color = F1),size = 3) +
  scale_color_viridis_c() + guides(color = 'none')+
  scale_x_continuous(name = 'Factor loadings by item and latent trait dimension') + 
  theme_bw()

g2 = ggplot(ld3dt[order(-F2),] %>% mutate(item = fct_reorder(item,F2)),aes(y = item,x = F2)) + 
  geom_segment(aes(y = item,yend = item,x = 0,xend = F2))+
  geom_point(aes(color = F2),size = 3) +
  scale_color_viridis_c() + guides(color = 'none')+
  scale_x_continuous(name = 'Factor loadings by item and latent trait dimension') + 
  theme_bw()
grid.arrange(g1,g2,ncol = 2)

ggplot(ld3dt,aes(x = F1,y = F2,label = item)) + geom_point() + geom_label_repel(max.overlaps = 10) + 
  scale_y_continuous(limits = c(-0.75,0.75)) +
    scale_x_continuous(limits = c(-0.75,0.75)) + theme_bw() 

```


```{r}
mod2_cov = mirt(Y,2,mtype = 'ideal',method = 'EM',formula = ~Q1_Focus + When_SLR + Q16_Risk_Agree + Q17_Action_Agree,covdata = predictor_dt,technical = list(NCYCLES = 1500))
mod3_cov = mirt(Y,3,mtype = 'ideal',method = 'EM',formula = ~Q1_Focus + When_SLR + Q16_Risk_Agree + Q17_Action_Agree,covdata = predictor_dt,technical = list(NCYCLES = 1500))
```

```{r}
summary(mod2_cov)
coef(mod2_cov)
```


```{r}
mod1 = bare_mods[[1]]
plot(mod1, type = 'trace', facet_items = TRUE)
plot(mod1, type = 'trace', facet_items = FALSE)

mod1@Fit
```


```{r}
itemplot(object = mod3,item = 3,type = 'info')
mod3 = bare_mods[[3]]
loads = summary(mod3, rotate = 'oblimin') #oblimin rotation
ld= data.table(data.table(loads$rotF),item = rownames(loads$rotF))
ggplot(ld,aes(x = F1,y = F2,z = F3))  + geom_point() + geom_text_repel(aes(label = item),max.overlaps = 15)+
  scale_y_continuous(limits = c(-0.7,0.7)) + 
  scale_x_continuous(limits = c(-0.7,0.7)) 
setnames(ld,c('F1','F2','F3'),c('x','y','z'))
library(tidyverse)
library(ggtern)
library(mirt)
library(data.table)
library(plotly)


pt = plot_ly(data=ld,z = ~z,y = ~y,x = ~x)
pt %>% add_markers()
?plot_ly
plot(mod, rotate = 'oblimin')
summary(loads$rotF)

scorestable <- fscores(mod, full.scores = FALSE) #save factor score table
ggplot(data.table(scorestable),aes(x = F1,y = F2)) + geom_point()

scorestable

```



*Identifying underlying trait dimensions*

As described above, an LTA model is essentially a factor analysis--thus, we can use typical factor analysis tools for identifying an appropriate number of dimensions. Figure \@ref(fig:figure_factor_analysis) plots Eigen values by factor number along with a series of non-graphical tests meant to identify an optimal number of factors. These tests are not all in agreement, ranging from a recommendation of 2 factors (the statistical "elbow" of the curve) to 17 (the number of factors with an Eigenvalue greater than 1). For parsimony, we select the lowest recommended value, *D* = 2, and fit an MLTA model with two underlying trait dimensions.

```{r figure_factor_analysis, echo = F,message = F,warning = F}
ev <- eigen(cor(Y)) # get eigenvalues
ap <- nFactors::parallel(subject=nrow(Y),var=ncol(Y),
  rep=100,cent=.05)

nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS,xlab = 'Factors',main = 'Scree plot of factor Eigenvalues')
```



*Identifying subgroups*

We take a similar approach to identifying an appropriate number of groups. Figure \@ref(fig:figure_k_means) hierarchically presents a series of k-means clustering results fit to different values of *k*. The top level shows a single cluster model (i.e., no subgroups), and the very bottom layer shows groups for *k* = 10. The arrows in figure \@ref(fig:figure_k_means) show how respondents change groupings as the number of clusters changes. At high k-values, we observe that the clusters are unstable--respondents who were grouped into separate clusters at lower k-values are now mixed up into totally new groupings. In this regard, *k* = 3 appears to be a good cluster value--at *k* = 4, clusters become less stable, while *k* = 2 appears to mask a distinction between two underlying subgroups.

```{r figure_k_means, echo = F,message = F,warning = F}
set.seed(24)
library(clustree)

k_vals = 1:10
tmp <- NULL
for (k in k_vals){
  tmp[k] <- kmeans(Y, k, nstart = 30)
}
df <- data.frame(tmp)
# add a prefix to the column names
colnames(df) <- k_vals
colnames(df) <- paste0("k",colnames(df))
# get individual PCA
df.pca <- prcomp(df, center = TRUE, scale. = FALSE)
ind.coord <- df.pca$x
ind.coord <- ind.coord[,1:2]
df <- bind_cols(as.data.frame(df), as.data.frame(ind.coord))
clustree(df, prefix = "k")

```

```{r message=F,warning=F,echo = F}
index2 = which(opts$D==D&opts$G==G&opts$fix==T)
group_probs = mlta_temp[[index2]]$z
gp = data.table(group_probs)
```

Given the results presented above, we fit a final MLTA model with *G* = 3 and *D* = 2, keeping item-response slopes fixed across subgroups. Using this model, figure \@ref(fig:figure_group_probability_map) shows the predicted probability of group membership. The total probability must sum to one. Most respondents have a very high probability of being in a single group, with a just a limited amount showing a more ambiguous prediction. Taking the highest probability for each respondent (across all three groups), the median maximum probability is `r round(median(apply(gp,1,max)),2)`, and the minimum is `r round(min(apply(gp,1,max)),2)`.


```{r figure_group_probability_map, echo=F, message=FALSE, warning=FALSE}
TernaryPlot(alab = "p(Group 1) \u2192", blab = "p(Group 2) \u2192", clab = "\u2190 p(Group 3)",
            point = 'up',atip = 'G1', btip = 'G2',ctip = 'G3',
            lab.col = c('red', 'darkgreen', 'blue'), tip.col = c('red','darkgreen','blue'),
            lab.cex = 0.8, grid.minor.lines = 0,
            grid.lty = 'solid', col = rgb(0.9, 0.9, 0.9), grid.col = 'white', 
            axis.col = rgb(0.6, 0.6, 0.6), ticks.col = rgb(0.6, 0.6, 0.6),
            axis.rotate = FALSE,
            padding = 0.08)
AddToTernary(points, coordinates = gp, pch = 21, cex = 1)
```


Just as respondents are clustered within groups, concepts are linked to underlying trait dimensions. We can plot the strength of these linkages by plotting the slopes for the logistic response functions--these are interpreted similarly to loadings in a factor analysis, in that a slope near 1 or -1 indicates a strong relationship between the variable and the underlying trait dimension, and a loading near 0 indicates a weak relationship.
```{r figure_factor_loadings, warning = F,message = F,echo = F,fig.height=5,fig.width = 5}
mod = mlta_temp[[index2]]

beta_dt = data.table(t(mod$w),item = colnames(Y))
beta_dt$group = concept_types$Type[match(beta_dt$item,concept_types$Vector)]
circles <- data.frame( x0 = 0, y0 = 0, r = 1)

#rotate factors for interpretation
library(psych)
beta_dt[,1:D] <- data.table(factor.rotate(f =as.matrix(beta_dt[,1:D]),plot = F,angle = 85))
library(ggforce)
ggplot() +
      geom_circle(data = circles,aes(x0 = x0,y0 = y0,r = r),lty = 2, col = 'grey50') +
  geom_vline(xintercept = 0,lty = 2,col = 'grey40') +
  geom_hline(yintercept = 0,lty = 2,col = 'grey40') + 
geom_text_repel(data = beta_dt[group!=if(DROP_BARRIERS){'Barrier'}else{'KEEP'},],aes(x = `Dim 1`,y = `Dim 2`,label = item,col = group,fill = group),
                size = 2.5,max.overlaps = 100,min.segment.length = 0.2,show.legend = F) +
    geom_point(data = beta_dt[group!=if(DROP_BARRIERS){'Barrier'}else{'KEEP'},],aes(x = `Dim 1`,y = `Dim 2`,label = item,col = group,fill = group),
               pch = 19,show.legend = T) +
    scale_fill_colorblind(name = 'Concept type') +
  scale_color_colorblind(name = 'Concept type') +
  ggtitle('Slope estimates ("loadings") for item-response functions on latent traits') +
  theme_bw() + 
  scale_x_continuous(name= 'Slope for dimension 1',limits = c(-1,1)) + 
  scale_y_continuous(name= 'Slope for dimension 2',limits = c(-1,1)) + 
  theme(axis.title = element_text(size = 10,inherit.blank = F,family = 'Times',,margin =c(1,1,1,1)),
        legend.position = c(0.9,0.2)) 
```



**RESULTS**  

**Correlation between external items and concept responses**  
Using Spearman's rho,  probability of Group 1 membership significantly correlated with higher level of involvement with SLR work. It also correlated with environmental and water special district organizations and negatively correlated with CBO organizations. This group is correlated with higher short term and long term awareness of SLR impacts and higher perceived regional agreement on SLR risks. 

Probability of Group 2 is significantly correlated with local government organizations but shows correlations with lower involvement levels, fewer SLR related work tasks (particularly project management and outreach), and fewer information sources used in SLR work. Negatively correlated with being in an NGO and correlated with lower short and long term SLR awareness, lower short and long term SLR concern, and later anticipated timing of SLR impacts. Also lower assessment of regional agreement on risks.

Probability of Group 3 membership significantly correlated with more work tasks related to SLR including project management and outreach, being in a CBO or NGO org, and showing more concern for both short and long term SLR impacts. Also correlated with anticipating impacts of SLR happening sooner in time and negatively correlated with being in a water special district or local government org.

```{r correlate_external_groups, echo=F,insert = F,warning = F,message = F}
#Create list of group probabilities for respondents------------------------
#looks like group_probs is the probabilities and Y is cooccurrence matrix with row names as respondent ID

group_prob <- as.data.frame(group_probs)
#create dataframe of Y (row names are respondent ID) and add in the group 1 and group 2 probabilities
RespGroups <- as.data.frame(Y)

RespGroups$P_G1 <- group_prob$V1
RespGroups$P_G2 <- group_prob$V2
RespGroups$P_G3 <- group_prob$V3

RespGroups$respondentID <- row.names(RespGroups)


#Match that back to survey results--------------------------------------
survey_orig <- as.data.frame(orig)
RespGroups <- as.data.frame(RespGroups)
survey_orig$respondentID <- survey_orig$ResponseId


merged_survey <- left_join(RespGroups, survey_orig, by='respondentID')

#Use merged_survey to find connections between groups and survey attributes--------------
#create additional variable assigning to G1 G2 or G3 based on which has higher probability

merged_survey$Group <- ifelse(merged_survey$P_G1>merged_survey$P_G2 & merged_survey$P_G1>merged_survey$P_G3, 1, 
                              ifelse(merged_survey$P_G2>merged_survey$P_G1 & merged_survey$P_G2>merged_survey$P_G3, 2,3))

#table(merged_survey$Group)

#Crosstabs of group assignments with other variables
#table(merged_survey$Group, merged_survey$Q1_Num)

#table(merged_survey$Group, merged_survey$Q2_Personal)
#table(merged_survey$Group, merged_survey$Q2_OneOrg)
#table(merged_survey$Group, merged_survey$Q2_MultiOrg)

#table(merged_survey$Group, merged_survey$Q4)

#table(merged_survey$Group, merged_survey$Q5)

#table(merged_survey$Group, merged_survey$Q8_Sum)

#table(merged_survey$Group, merged_survey$Q8_Exec)
#table(merged_survey$Group, merged_survey$Q8_Policy)
#table(merged_survey$Group, merged_survey$Q8_Planning)
#table(merged_survey$Group, merged_survey$Q8_Science)
#table(merged_survey$Group, merged_survey$Q8_Gov)
#table(merged_survey$Group, merged_survey$Q8_PM)
#table(merged_survey$Group, merged_survey$Q8_Advocacy)
#table(merged_survey$Group, merged_survey$Q8_Outreach)
#table(merged_survey$Group, merged_survey$Q8_Other)

#table(merged_survey$Group, merged_survey$Q32_Sum)

#table(merged_survey$Group, merged_survey$Q11_STAware)
#table(merged_survey$Group, merged_survey$Q11_LTAware)

#table(merged_survey$Group, merged_survey$Q12_STConcern)
#table(merged_survey$Group, merged_survey$Q12_LTConcern)

#table(merged_survey$Group, merged_survey$WhenSLR)

#table(merged_survey$Group, merged_survey$RiskAgree)
#table(merged_survey$Group, merged_survey$ActionAgree)

#Correlations between group probabilities and other variables
library(devtools)

correlations <- subset(merged_survey, select= c('P_G1', 'P_G2', 'P_G3', 'Q1_Num', 'Q2_Personal', 'Q2_OneOrg', 'Q2_MultiOrg', 'Q8_Sum', 'Q8_Exec', 'Q8_Policy', 'Q8_Planning', 'Q8_Science', 'Q8_Gov', 'Q8_PM', 'Q8_Advocacy', 'Q8_Outreach', 'Q8_Other', 'Q32_Sum', 'Q4_Ag', 'Q4_CBO', 'Q4_Ed', 'Q4_Enviro', 'Q4_EnviroSD', 'Q4_Fed', 'Q4_LocalGov', 'Q4_Media', 'Q4_Multijuris', 'Q4_Multistake', 'Q4_NGO', 'Q4_Other', 'Q4_Political', 'Q4_RegGov', 'Q4_State', 'Q4_Trade', 'Q4_WaterSD', 'Q11_STAware', 'Q11_LTAware', 'Q12_STConcern', 'Q12_LTConcern', 'WhenSLR', 'RiskAgree', 'ActionAgree'))


correlations[is.na(correlations)]=0


correlationmatrix <- cor(correlations, method="kendall")
correlationmatrix_sp <- cor(correlations, method="spearman")


library("corrplot")
library("Hmisc")
#note that corrplot which I used for this only allows pearson and spearman- if we want kendall will need to do it another way
data.rcorr.pear <- rcorr(as.matrix(correlations), type="pearson")
data.rcorr.sp <- rcorr(as.matrix(correlations), type="spearman")

data.coeff.sp <- data.rcorr.sp$r
data.p.sp <- data.rcorr.sp$P

significantp <- data.p.sp[,1:3]
threecolumncorr <- data.coeff.sp[,1:3]

significantp <- as.data.frame(significantp)
threecolumncorr <- as.data.frame(threecolumncorr)

significantp$PG1_p <- significantp$P_G1
significantp$PG2_p <- significantp$P_G2
significantp$PG3_p <- significantp$P_G3

threecolumncorr$PG1_r <- threecolumncorr$P_G1
threecolumncorr$PG2_r <- threecolumncorr$P_G2
threecolumncorr$PG3_r <- threecolumncorr$P_G3


significantp <- significantp[,4:6]
threecolumncorr <- threecolumncorr[,4:6]

threecolumncorr$names <- rownames(threecolumncorr)

corrmatrix <- as.data.frame(threecolumncorr$names)
corrmatrix$PG1_r <- threecolumncorr$PG1_r
corrmatrix$PG1_p <- significantp$PG1_p
corrmatrix$PG2_r <- threecolumncorr$PG2_r
corrmatrix$PG2_p <- significantp$PG2_p
corrmatrix$PG3_r <- threecolumncorr$PG3_r
corrmatrix$PG3_p <- significantp$PG3_p

corrmatrix.sigG1 <- subset(corrmatrix, corrmatrix$PG1_p<0.05)
corrmatrix.sigG2 <- subset(corrmatrix, corrmatrix$PG2_p<0.05)
corrmatrix.sigG3 <- subset(corrmatrix, corrmatrix$PG3_p <0.05)

```


*respondents mapped on latent variables*
We can map each individual survey respondent on the (D = 2) latent variables. But, because the model probabilistically clusters respondents by group (G = 3), what is actually estimated is the posterior mean for each individual on each latent variable conditional on being in group G. So, I use the group assignment probabilities to select the 'best' posterior means for each respondent.

```{r,echo = F,message = F,warning = F}
g_index = apply(mod$z,1,which.max)
list_of_locs = lapply(seq_along(g_index),function(i) mod$mu[i,,g_index[i]])
locs_df = data.table(do.call(rbind,list_of_locs))
locs_df$group = g_index
ggplot(locs_df,aes(x = V1,y = V2,col = as.factor(group))) + 
  geom_point() +
  scale_y_continuous(name = 'Location on latent dimension 2') + 
  scale_x_continuous(name = 'Location on latent dimension 1') + 
  scale_color_brewer(type = 'qual',palette = 2,name = 'Predicted group') + 
  theme(legend.position = c(0.8,0.1)) + 
  ggtitle('Estimated location of respondents in latent space') + 
  NULL

```

Obviously, this is super messy. There is clearly variance in positioning within and between groups, but the groups themselves don't correspond directly to positions in the latent space. To some extent, that makes sense -- groups are based on responses, and latent dimensions are based on responses, but the groups and latent dimensions aren't connected at all so the "solution" to the latent dimension model and the "solution" to the respondent grouping model can organize the data differently.

When plotting individual dimension scores by actor level variables, few trends emerge.For the most part, average scores are around zero for all dimensions by different respondent characteristics. Based on the plots,  D1 (top down to bottom up) average scores appear higher for Federal Gov, and Enviro Group actors while D2 (built enviro/econ to EJ/enviro)  is higher for Local Gov actors. There is a very weak trend visible in the plots for D1 to increase and D2 to decrease with increasing numbers of info sources used in SLR work. Also weak decline in average D1 scores and increase in average D2 scores for increasing perceived regional risk agreement. 

Correlation values can determine if these observed trends are statistically significant. Higher D1 average scores is significantly correlated with Enviro Group and Fed Gov actors and higher D2 average scores is significantly correlated with Local Gov and State actors. Higher concern for short term SLR impacts is significantly correlated with higher D1 scores and lower D2 scores. Timing of SLR is negatively correlated with D1 average scores (later anticipated SLR impacts has higher D1 scores). Meanwhile higher perceived agreement of actions regionally and lower short and long term concern for SLR impacts is correlated with higher D2 average scores. 
```{r,echo = F,warnings = F,message = F}
sub = data.table(orig[orig$ResponseId %in% rownames(Y),])
sub[,V1:=NULL]
locs_df2 = cbind(locs_df,sub)

#Plot of D scores by org type
ggplot(locs_df2,aes(y = Q4)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by org. type') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by level of involvement
locs_df2$Q1_Fact <- as.factor(locs_df2$Q1_Num)
levels(locs_df2$Q1_Fact) <- c("Major Aspect > 5 years", "Major Aspect 1-5 years", "Major Aspect < 1 year", "Routine Involvement", "Occasional Involvement")

ggplot(locs_df2,aes(y = Q1_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by level of involvement') +
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by Risk Agreement
locs_df2$RiskAgree_Fact <- as.factor(locs_df2$RiskAgree)
levels(locs_df2$RiskAgree_Fact) <- c("Very Low", "Low", "Not Very High", "Fairly High", "High", "Very High")

ggplot(locs_df2,aes(y = RiskAgree_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by assessed regional risk agreement') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

```

```{r plots_d_scores,echo=F,insert = F,warning = F,message = F}}

#Plot of D scores by number of task types 
locs_df2$Q8_Fact <- as.factor(locs_df2$Q8_Sum)
levels(locs_df2$Q8_Fact)

ggplot(locs_df2,aes(y = Q8_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by number of tasks') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by sum of info types used
locs_df2$Q32_Fact <- as.factor(locs_df2$Q32_Sum)

ggplot(locs_df2,aes(y = Q32_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by number of info types used') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by short term SLR awareness
ggplot(locs_df2,aes(y = Q11_1)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by awareness about short term SLR impacts') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D Scores by long term SLR awareness
ggplot(locs_df2,aes(y = Q11_2)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by awareness of long term SLR impacts') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by short term SLR concern
ggplot(locs_df2,aes(y = Q12_1)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by concern of short term SLR impacts') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by long term SLR concern
ggplot(locs_df2,aes(y = Q12_2)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by concern of long term SLR impacts') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')

#Plot of D scores by anticipated SLR impacts timing 
locs_df2$WhenSLR_Fact <- as.factor(locs_df2$WhenSLR)
levels(locs_df2$WhenSLR_Fact) <- c("Already Felt", "Starting Now", "Next Few Years", "Next Few Decades", "By 2100", "Later than 2100")
ggplot(locs_df2,aes(y = WhenSLR_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by expected timing of SLR impacts') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')



#Plot of D scores by Action Agreement
locs_df2$ActionAgree_Fact <- as.factor(locs_df2$ActionAgree)
levels(locs_df2$ActionAgree_Fact) <- c("Very Low", "Low", "Not Very High", "Fairly High", "High", "Very High")

ggplot(locs_df2,aes(y = ActionAgree_Fact)) + 
  geom_boxplot(aes(x = V1,col = 'D1'),width = 0.4,position = position_nudge(y = -0.25),fill = NA)+
  geom_boxplot(aes(x = V2,col = 'D2'),width = 0.4,position = position_nudge(y = 0.25),fill = NA)+
  ggtitle('position on latent dimensions by assessed regional action agreement') + 
  scale_color_tableau(name = 'dimension') +
  scale_x_continuous(name = 'location')
```


```{r correlate_D_scores_actors, echo=F,insert = F,warning = F,message = F}
correlations_d <- subset(locs_df2, select= c("V1", "V2", 'Q1_Num', 'Q2_Personal', 'Q2_OneOrg', 'Q2_MultiOrg', 'Q8_Sum', 'Q8_Exec', 'Q8_Policy', 'Q8_Planning', 'Q8_Science', 'Q8_Gov', 'Q8_PM', 'Q8_Advocacy', 'Q8_Outreach', 'Q8_Other', 'Q32_Sum', 'Q4_Ag', 'Q4_CBO', 'Q4_Ed', 'Q4_Enviro', 'Q4_EnviroSD', 'Q4_Fed', 'Q4_LocalGov', 'Q4_Media', 'Q4_Multijuris', 'Q4_Multistake', 'Q4_NGO', 'Q4_Other', 'Q4_Political', 'Q4_RegGov', 'Q4_State', 'Q4_Trade', 'Q4_WaterSD', 'Q11_STAware', 'Q11_LTAware', 'Q12_STConcern', 'Q12_LTConcern', 'WhenSLR', 'RiskAgree', 'ActionAgree'))

correlations_d[is.na(correlations_d)]=0
correlationmatrix_d <- cor(correlations_d, method="pearson")
correlationmatrix_d_sp <- cor(correlations_d, method="spearman")

library("corrplot")
library("Hmisc")
#note that corrplot which I used for this only allows pearson and spearman- if we want kendall will need to do it another way
data.rcorr.d <- rcorr(as.matrix(correlations_d), type="pearson")
data.rcorr.d.sp <- rcorr(as.matrix(correlations_d), type="spearman")

data.coeff.d.sp <- data.rcorr.d.sp$r
data.p.d.sp <- data.rcorr.d.sp$P
data.p.d.sp

significantp.d <- data.p.d.sp[,1:2]
threecolumncorr.d <- data.coeff.d.sp[,1:2]

significantp.d <- as.data.frame(significantp.d)
threecolumncorr.d <- as.data.frame(threecolumncorr.d)

significantp.d$V1_p <- significantp.d$V1
significantp.d$V2_p <- significantp.d$V2

threecolumncorr.d$V1_r <- threecolumncorr.d$V1
threecolumncorr.d$V2_r <- threecolumncorr.d$V2


significantp.d <- significantp.d[,4:6]
threecolumncorr.d <- threecolumncorr.d[,4:6]

threecolumncorr.d$names <- rownames(threecolumncorr.d)

corrmatrix.d <- as.data.frame(threecolumncorr.d)
corrmatrix.d$V1_r <- threecolumncorr.d$V1_r
corrmatrix.d$V1_p <- significantp.d$V1_p
corrmatrix.d$V2_r <- threecolumncorr.d$V2_r
corrmatrix.d$V2_p <- significantp.d$V2_p

?subset()
corrmatrix.sigV1.d <- subset(corrmatrix.d, corrmatrix.d$V1_p<0.05)
corrmatrix.sigV2.d <- subset(corrmatrix.d, corrmatrix.d$V2_p<0.05)


```

```{r org count, echo = F, warnings = F, message = F}
org_count = locs_df2[,.N,by=.(group,Q4)]
tot_count = locs_df2[,.N,by=.(group)]
setnames(tot_count,'N','group_total')
org_count = merge(org_count,tot_count)
ggplot(data =org_count,
  aes(fill = Q4,x = group,y = N/group_total ))+
    geom_col(position = position_dodge()) +
  coord_flip()  +
 scale_y_continuous(labels = scales::percent,name = '% of group total')
```



**groups mapped to item-response loadings**

We can then evaluate the intercept terms in each logistic response function to identify which items load heavily by group. Ignoring the model slope parameters. Here, it's clear that some items are identified by both groups (e.g., stormwater, transportation) while others are more excluvisely related to one and not the other (e.g., concern about DACs). Some are rare in both, like "commercial" and "property value". This also begins to reveal why increased dimensionality doens't seem to help model fit very much, many items are about as likely to be selected by one group as the other. Heuristically, items below the dashed line are more strongly associated with Group 1, and above are more strongly associated with Group 2.

```{r, message=F,warning=F,echo = F}
beta_dt = data.table(t(mod$b),keep.rownames = T)
beta_dt$concept = colnames(Y)
beta_dt$type = concept_types$Type[match(beta_dt$concept,concept_types$Vector)]


# 
g_base = ggplot(beta_dt) + geom_abline(a =0, b = 1,lty = 2) +
  scale_x_continuous(limits = c(-4,4)) +
  scale_y_continuous(limits = c(-4,4))
g1_vs_g2 = g_base +
  geom_point(aes(x = `Group 1`,y = `Group 2`)) +
  geom_text_repel(max.overlaps = 15,aes(x = `Group 1`,y = `Group 2`,label = concept))
g2_vs_g3 = g_base +
  geom_point(aes(x = `Group 2`,y = `Group 3`)) +
  geom_text_repel(max.overlaps = 15,aes(x = `Group 2`,y = `Group 3`,label = concept))
g1_vs_g3 = g_base +
  geom_point(aes(x = `Group 1`,y = `Group 3`)) +
  geom_text_repel(max.overlaps = 15,aes(x = `Group 1`,y = `Group 3`,label = concept))
grid.arrange(g1_vs_g2,g2_vs_g3,g1_vs_g3,ncol = 2,
             top ='Intercept estimates for item-response by group (p = 1 / exp(-beta))')

```


```{r, warning = F,message= F,echo = F}
library(plotly)



fig <- plot_ly(beta_dt, x = ~ `Group 1`, y = ~ `Group 2`, z = ~`Group 3`,
               color = ~type,
               text = ~concept, hoverinfo = 'text')
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(
                      title= list(title = 'Group item-responese intercepts'),
                       xaxis = list(title = 'intercept, group 1'),
                     yaxis = list(title = 'intercept, group 2'),
                     zaxis = list(title = 'intercept, group 3')))
fig
```


```{r}
#keepConcepts = network.vertex.names(bip_net)[{bip_net %v% 'Concept_Type'} %in% c('Policy','Concern')]

coFreq_all = rbindlist(lapply(1:G,function(g) {
coFreq = data.table(reshape2::melt(crossprod(Y[g_index==g,])))
coFreq$Var1_Type = {bip_net %v% 'Concept_Type'}[match(coFreq$Var1,bip_net %v% 'vertex.names')]
coFreq$Var2_Type = {bip_net %v% 'Concept_Type'}[match(coFreq$Var2,bip_net %v% 'vertex.names')]
coFreq = coFreq[Var1_Type=='Concern'&Var2_Type=='Policy',]
coFreq$group = paste0('G',g)
coFreq}))

coFreq_all$Var1 <- as.character(coFreq_all$Var1 )
coFreq_all$Var2 <- as.character(coFreq_all$Var2 )
coFreq_all <- coFreq_all[order(Var1,Var2),][value>0,]

ggplot(coFreq_all[,sum(value),by=.(Var1,Var2,Var1_Type,Var2_Type)],
       aes(y = V1, axis1 = Var1, axis2 = Var2)) +
  geom_alluvium(width = 1/12,aes(alpha = V1),fill= 'grey20') + 
  geom_stratum(fill = "black", colour = 'grey',width = .1) + 
  ggtitle('Concern and policy co-occurence') + 
  geom_label(stat = "stratum", aes(label = after_stat(stratum)))+
  scale_x_discrete(limits = c("Concern", "Policy"), expand = c(.05, .05)) +
  guides(alpha = F)

  
```


THIS IS THE SAME PLOT BUT FACETED SO EACH GROUP IS SEPARATE

```{r,warning=F,message = F,echo = F,fig.height = 15}
ggplot(coFreq_all,
       aes(y = value, axis1 = Var1, axis2 = Var2)) +
  geom_alluvium(width = 1/12,aes(alpha = value),fill= 'grey20') + 
  facet_wrap(~group,ncol = 1,scale = 'free_y') +
  geom_stratum(fill = "black", colour = 'grey',width = .1) + 
  ggtitle('Concern and policy co-occurence') + 
  geom_label(stat = "stratum", aes(label = after_stat(stratum)))+
  scale_x_discrete(limits = c("Concern", "Policy"), expand = c(.05, .05)) +
  guides(alpha = F)
```

```{r, echo=F,insert = F,warning = F,message = F}

#Attempting to change colors and labels based on flows- only has label for those with more than 25 responses for a group linking policy to concern, colored so greener/yellower is more frequency 
ggplot(coFreq_all,
       aes(y = value, axis1 = Var1, axis2 = Var2)) +
  geom_alluvium(width = 1/12,aes(alpha = value, fill=value)) + 
  scale_fill_continuous(type="viridis")+
  facet_wrap(~group,ncol = 1,scale = 'free_y') +
  geom_stratum(fill = "grey", colour = 'black',width = .1) + 
  geom_label_repel(data=subset(coFreq_all, value>25), stat="stratum", aes(label=after_stat(stratum)))+
  ggtitle('Concern and policy co-occurence') +
  scale_x_discrete(limits = c("Concern", "Policy"), expand = c(.05, .05)) +
  guides(alpha = F)
```

```{r, echo=F,warning = F,message = F}
#Attempting to use ranking to color flows by rank and label top flows... ended up just labeling those with rank > 400 (top 25ish) but should've done top 5 for each group but couldn't figure it out... can keep trying
coFreq_all$Rank <- frank(coFreq_all, value, ties.method="random")
ggplot(coFreq_all,
       aes(y = value, axis1 = Var1, axis2 = Var2)) +
  geom_alluvium(width = 1/12,aes(alpha = value, fill=Rank)) + 
  scale_fill_continuous(type="viridis")+
  facet_wrap(~group,ncol = 1,scale = 'free_y') +
  geom_stratum(fill = "grey", colour = 'black',width = .1) + 
  geom_label_repel(data=subset(coFreq_all, Rank>350), stat="stratum", aes(label=after_stat(stratum)))+
  ggtitle('Concern and policy co-occurence') +
  scale_x_discrete(limits = c("Concern", "Policy"), expand = c(.05, .05)) +
  guides(alpha = F)

```

**more results**  
Correlations between probability of group membership and response choices reveals certain trends in responses that fits with earlier correlations of respondent characteristics and group probabilities

Can roughly group policies along D1 (top down vs. bottom up) and concerns along D2 (built enviro/econ/regional vs. EJ/social/environmental) to figure out if group probability correlates with certain categories of responses

Top down policies: existing agency, new regional authority, information platform, overall SLR plan, streamling permits, lobby for state/fed funding
Bottom up: local response, focus on DACs, vulnerability assessments, collaboration, visioning, local taxes, innovative design, green infrastructure

Built/econ/regional: transpo, Water supply, stormwater, energy, commercial, econ growth, property value
Enviro/ej/social/local: ecosystem, erosion, DACs, Public Health, housing

Higher Group 1 probability, which correlated with more Enviro and Water SD with more SLR awareness and level of involvement are correlated with more often selecting streamlining permits and local taxes as policies and more concern for transportation, stormwater, erosion with less concern for or selection of policies related to DACs and less selection of top down policies like information platform, overall SLR plan, or new regional authority

Group 1 could be categorized as special districts with more SLR awareness/involvement focused on local level infrastructure implementation with concerns for ecosystem and infrastructure functioning

Higher Group 2 probability, which correlated with local government actors with lower involvement and awareness and seeing SLR impacts later, was correlated with more selection of top down policies (SLR plan, lobbying for fed/state funding, information platform) and more concern for built environment (water, stormwater, energy) but also for commercial and property value concerns with negative correlations to housing, public health, and DACs concerns or DACs focused policies

Group 2 could be categorized as local government actors with less sLR concern and involvement focused on local economic growth and infrastructure favoring top down policies

Higher Group 3 probability, which correlated with CBOs and NGOs and more outreach tasks and higher concerns and seeing SLR impacts sooner, correlated with selection of social concerns (DACs, housing and public health) with negative correlations for selecting environmental, economic, or infrastructure concerns (water supply, stormwater, energy, erosion, ecosystem health, property value, commercial), and correlated with selection of bottom up policies (focus on DACs, visioning process) with negative correlations with infrastructure policies (permits, GI)

Group 3 could be categorized as NGO/CBOs with higher SLR concerns and focused on social concerns of SLR impacts with priorities of socially based and bottom up policies

```{r correlate_groups_responses, echo=F,insert = F,warning = F,message = F}
correlations_counts <- subset(RespGroups, select= c("P_G1", "P_G2", "P_G3", "SLR Plan", "Vulnerable", "Local Tax","Lobby", "Permits", "Info Platform", "DACs", "Green Infra", "Vision", "Innov Design", "Local Response", "Regional Authority", "Existing Agency", "Collab", "Transpo", "Water", "Stormwater", "Energy", "Ecosystem", "Erosion", "Commercial", "DACsC", "Econ Growth", "Property Value", "Housing", "Public Health"))

correlations_counts[is.na(correlations_counts)]=0
correlationmatrix_counts <- cor(correlations_counts, method="kendall")
correlationmatrix_counts_sp <- cor(correlations_counts, method="spearman")

library("corrplot")
library("Hmisc")
#note that corrplot which I used for this only allows pearson and spearman- if we want kendall will need to do it another way
data.rcorr.count.pear <- rcorr(as.matrix(correlations_counts), type="pearson")
data.rcorr.count.sp <- rcorr(as.matrix(correlations_counts), type="spearman")

data.coeff.count.sp <- data.rcorr.count.sp$r
data.p.count.sp <- data.rcorr.count.sp$P
data.p.count.sp

significantp.count <- data.p.count.sp[,1:3]
threecolumncorr.count <- data.coeff.count.sp[,1:3]

significantp.count <- as.data.frame(significantp.count)
threecolumncorr.count <- as.data.frame(threecolumncorr.count)

significantp.count$PG1_p <- significantp.count$P_G1
significantp.count$PG2_p <- significantp.count$P_G2
significantp.count$PG3_p <- significantp.count$P_G3

threecolumncorr.count$PG1_r <- threecolumncorr.count$P_G1
threecolumncorr.count$PG2_r <- threecolumncorr.count$P_G2
threecolumncorr.count$PG3_r <- threecolumncorr.count$P_G3


significantp.count <- significantp.count[,4:6]
threecolumncorr.count <- threecolumncorr.count[,4:6]

threecolumncorr.count$names <- rownames(threecolumncorr.count)

corrmatrix.count <- as.data.frame(threecolumncorr.count)
corrmatrix.count$PG1_r <- threecolumncorr.count$PG1_r
corrmatrix.count$PG1_p <- significantp.count$PG1_p
corrmatrix.count$PG2_r <- threecolumncorr.count$PG2_r
corrmatrix.count$PG2_p <- significantp.count$PG2_p
corrmatrix.count$PG3_r <- threecolumncorr.count$PG3_r
corrmatrix.count$PG3_p <- significantp.count$PG3_p

?subset()
corrmatrix.sigG1.count <- subset(corrmatrix.count, corrmatrix.count$PG1_p<0.05)
corrmatrix.sigG2.count <- subset(corrmatrix.count, corrmatrix.count$PG2_p<0.05)
corrmatrix.sigG3.count <- subset(corrmatrix.count, corrmatrix.count$PG3_p <0.05)

#Double check with pearson

data.coeff.count.p <- data.rcorr.count.pear$r
data.p.count.p <- data.rcorr.count.pear$P
data.p.count.p

significantp.count.pear <- data.p.count.p[,1:3]
threecolumncorr.count.pear <- data.coeff.count.p[,1:3]

significantp.count.pear <- as.data.frame(significantp.count.pear)
threecolumncorr.count.pear <- as.data.frame(threecolumncorr.count.pear)

significantp.count.pear$PG1_p <- significantp.count.pear$P_G1
significantp.count.pear$PG2_p <- significantp.count.pear$P_G2
significantp.count.pear$PG3_p <- significantp.count.pear$P_G3

threecolumncorr.count.pear$PG1_r <- threecolumncorr.count.pear$P_G1
threecolumncorr.count.pear$PG2_r <- threecolumncorr.count.pear$P_G2
threecolumncorr.count.pear$PG3_r <- threecolumncorr.count.pear$P_G3


significantp.count.pear <- significantp.count.pear[,4:6]
threecolumncorr.count.pear <- threecolumncorr.count.pear[,4:6]

threecolumncorrv.pear$names <- rownames(threecolumncorr.count.pear)

corrmatrixp.count <- as.data.frame(threecolumncorr.count.pear)
corrmatrixp.count$PG1_r <- threecolumncorr.count.pear$PG1_r
corrmatrixp.count$PG1_p <- significantp.count.pear$PG1_p
corrmatrixp.count$PG2_r <- threecolumncorr.count.pear$PG2_r
corrmatrixp.count$PG2_p <- significantp.count.pear$PG2_p
corrmatrixp.count$PG3_r <- threecolumncorr.count.pear$PG3_r
corrmatrixp.count$PG3_p <- significantp.count.pear$PG3_p

?subset()
corrmatrix.sigG1.p.count <- subset(corrmatrixp.count, corrmatrixp.count$PG1_p<0.05)
corrmatrix.sigG2.p.count <- subset(corrmatrixp.count, corrmatrixp.count$PG2_p<0.05)
corrmatrix.sigG3.p.count <- subset(corrmatrixp.count, corrmatrixp.count$PG3_p <0.05)

```

**more results**  


**DISCUSSION**


**CONCLUSION**






